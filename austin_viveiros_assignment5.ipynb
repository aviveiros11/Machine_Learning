{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Python\n",
    "\n",
    "\n",
    "For this course, we are going to use Jupyter notebook as our environment for developing Python code.\n",
    "refer to https://jupyter.readthedocs.io/en/latest/content-quickstart.html on the instructions how to install it, the easiest way is to install from Anaconda (https://www.anaconda.com/download/) website, make sure you install with Python 3.6.\n",
    "\n",
    "Also, it is good for the students who are not familiar with python (or they need a quick refreshment) to follow Jim Bagrow tutorial http://bagrow.com/ds1/whirlwindtourpython/00-Title.html. \n",
    "\n",
    "All the assignments to be written in Python 3.6 and can be run using Jupyter on one of the following Internet browsers (Chrome, Safari or Firefox), these are the browsers that officially supported by jupyter.\n",
    "\n",
    "<u> Note: for this assignment, submit your local copy of this page, running on IPython. Submit the file to Blackboard under Assignment5 using this file format:</u> <b>Yourfirstname_lastname_Assignment5.ipynb</b> \n",
    "\n",
    "#### <b>Deadline</b>: <u>Dec-6-2019 11:59 PM.</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting started: Installing Numpy, Keras and TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras is a high-level Python API that allows you to easily construct, train, and apply neural networks.\n",
    "However, Keras is not a neural network library itself and depends on one of several neural network backends. We will use the Tensorflow backend. TensorFlow is an open-source library for neural networks (and other mathematical models based on sequences of matrix and tensor computations), originally developed by Google.Also, Keras uses numpy data structures. \n",
    "\n",
    "Installing Numpy, TensorFlow and Keras: \n",
    "\n",
    "We suggest that you use the Python package management system pip. \n",
    "On most systems, the following commands will work:\n",
    "\n",
    "- $ pip install numpy matplotlib.\n",
    "\n",
    "- $ pip install tensorflow\n",
    "\n",
    "- $ pip install keras\n",
    "\n",
    "### OR Using Anaconda (Easy and Prefered)\n",
    "\n",
    "- $ conda install keras scikit-learn pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this will likely install the CPU version of TensorFlow that does not use the GPU to speed up neural network training. For this assignment, training on the CPU will be sufficient, but if your computer has a GPU (or you want to try running the assignment in the cloud), follow the installation instructions on the tensorflow page. \n",
    "\n",
    "If you get stuck during the installation, you can find installation instructions for each package here: \n",
    "\n",
    "- Tensorflow: https://www.tensorflow.org/install/ \n",
    "- Keras: https://keras.io/#installation \n",
    "\n",
    "<b>I highly recommend that </b> you read and run these tutorials before you start this assignment. \n",
    "- https://www.tensorflow.org/tutorials/keras/classification\n",
    "- https://www.tensorflow.org/tutorials/images/cnn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "### Introduction\n",
    "In this assignment you will use the Keras Neural Network API for Python to build neural networks for image classification. \n",
    "\n",
    "\n",
    "#### Data Set\n",
    "\n",
    "We will work on the CIFAR-10 image data set  described here: https://www.cs.toronto.edu/~kriz/cifar.html.\n",
    "\n",
    "The data set contains 60.000 images labeled with 10 different categories:\n",
    "\n",
    "Numeric ID\tCategory Name\n",
    "- 0\tairplane\n",
    "- 1\tautomobile\n",
    "- 2\tbird\n",
    "- 3\tcat\n",
    "- 4\tdeer\n",
    "- 5\tdog\n",
    "- 6\tfrog\n",
    "- 7\thorse\n",
    "- 8\tship\n",
    "- 9\ttruck\n",
    "\n",
    "\n",
    "Each image is 32x32 pixels large and there are three color channels (red, green blue). Each image can therefore be represented as three 32x32 matrices or one 32x32x3 cube.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import cifar10\n",
    "from keras import Sequential \n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Flatten, Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. (20 pts) - Loading the CIFAR-10 Data\n",
    "\n",
    "The following code fragment imports the CIFAR-10 data using Keras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "(xtrain, ytrain), (xtest, ytest) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(xtrain.shape)\n",
    "print(ytrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32, 32, 3)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(xtest.shape)\n",
    "print(ytest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the training data into training and validation (40000 for training, and 10000 for validation). Thus you have xtrain, ytrain, xvalid, yvalid, xtest, and ytest are numpy n-dimension arrays contains the training validation and testing data.\n",
    "\n",
    "The input training data (xtrain) is a 4-dimensional array containing 40000 images, each of them a 32x32x3 tensor. Numpy arrays can be indexed like nested Python lists, so xtrain[0] will give you the first 32x32x3 image.\n",
    "\n",
    "The input label (ytrain) is a vector containing the numeric class for each image (see table above for what the numeric IDs mean). For example, xtrain[0] is an image of a frog and therefore ytrain[0] contains the value 6. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Images\n",
    "If you want to take a look at the individual images, you can do so using matplotlib (this step is optional). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x644ac0550>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(xtrain[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b.[20 Pnts] 1-hot representation for class labels\n",
    "\n",
    "The output layer of the neural networks we will train will contain 10 neurons corresponding to the 10 classes. The classifier predicts the class whose corresponding neuron has the highest activation. We need to convert the numeric indices for each image into a 1-hot vector of length 10, so that the for class label n the n-th element is 1 and all other elements are 0. For example, if the class label is 6, we should get the 1-hot vector [0 0 0 0 0 0 1 0 0 0].\n",
    "The class labels for the entire training and set should then be represented as a 50000x10 matrix, and the testing data as a 10000x10 matrix (there are 10k test images). \n",
    "\n",
    "Write the function load_cifar10(), which should load the cifar-10 data as described above and should return 6 numpy arrays xtrain, ytrain_1hot, xval, yval_1hot, xtest, ytest_1hot. Your function should convert the y arrays into the 1-hot representation. You can either do this using loops (slow), using numpy fancy indexing (see numpy documentation), or by using appropriate functions in the numpy or Keras API. \n",
    "\n",
    "Your function should also do the following normalization on the data. The R,G and B values for each pixel range between 0 and 255. Before returning the training data, normalize it so that these value range between 0.0 and 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar10():\n",
    "    ''' '''    \n",
    "    # add your code here...\n",
    "    (xtrain,ytrain),(xtest,ytest) = cifar10.load_data()\n",
    "    xtrain,xval,ytrain,yval = train_test_split(xtrain,ytrain,test_size=0.2,random_state=40)\n",
    "   \n",
    "    ytrain_1hot = to_categorical(ytrain)\n",
    "    yval_1hot = to_categorical(yval)\n",
    "    ytest_1hot = to_categorical(ytest)\n",
    "    #Normalizing \n",
    "    xtrain = xtrain/255\n",
    "    xval = xval/255\n",
    "    xtest = xtest/255\n",
    "    \n",
    "    return xtrain, xval, xtest, ytrain_1hot, yval_1hot, ytest_1hot\n",
    "\n",
    "xtrain,xval,xtest,ytrain_1hot,yval_1hot,ytest_1hot = load_cifar10()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 32, 32, 3)\n",
      "(40000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(xtrain.shape)\n",
    "print(ytrain_1hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32, 32, 3)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(xval.shape)\n",
    "print(yval_1hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32, 32, 3)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(xtest.shape)\n",
    "print(ytest_1hot.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32))"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain_1hot[0], yval_1hot[1], ytest_1hot[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. [20 Pnts]  In this task, you will implement an MLP network using keras.Sequential method with:\n",
    "\n",
    "- Batch size: 16. \n",
    "- Number of hidden layers: 1 (100 neuron).\n",
    "- use SGD optimizer, Learning Rate: 0.01.\n",
    "- #of epochs 10.\n",
    "- Use softmax layer for your output.\n",
    "- use Relu as your activation function.\n",
    "\n",
    "Keep all other hyperparameters (activation function, etc.) at their default settings.\n",
    "\n",
    "\n",
    "Find the performance (accuracy) of your model on the validation set and test set after training for 10 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "40000/40000 [==============================] - 14s 352us/step - loss: 1.9288 - acc: 0.3100\n",
      "Epoch 2/10\n",
      "40000/40000 [==============================] - 10s 250us/step - loss: 1.7587 - acc: 0.3797\n",
      "Epoch 3/10\n",
      "40000/40000 [==============================] - 11s 280us/step - loss: 1.6826 - acc: 0.4063\n",
      "Epoch 4/10\n",
      "40000/40000 [==============================] - 10s 252us/step - loss: 1.6304 - acc: 0.4265\n",
      "Epoch 5/10\n",
      "40000/40000 [==============================] - 10s 250us/step - loss: 1.5924 - acc: 0.4392\n",
      "Epoch 6/10\n",
      "40000/40000 [==============================] - 10s 255us/step - loss: 1.5597 - acc: 0.4502\n",
      "Epoch 7/10\n",
      "40000/40000 [==============================] - 10s 252us/step - loss: 1.5337 - acc: 0.4622\n",
      "Epoch 8/10\n",
      "40000/40000 [==============================] - 11s 278us/step - loss: 1.5114 - acc: 0.4684\n",
      "Epoch 9/10\n",
      "40000/40000 [==============================] - 11s 269us/step - loss: 1.4889 - acc: 0.4764\n",
      "Epoch 10/10\n",
      "40000/40000 [==============================] - 12s 292us/step - loss: 1.4715 - acc: 0.4823\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_7 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 308,310\n",
      "Trainable params: 308,310\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "10000/10000 [==============================] - 3s 280us/step\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(32, 32, 3)))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "sgd = SGD(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=sgd,metrics=['accuracy'])\n",
    "model.fit(xtrain, ytrain_1hot, epochs=10)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. [10 Pnts] How many parameters in the model implemented in b?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>The model has a total of 308,310 parameters</h3> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. [10 Pnts] At which epoch your model starts to overfit? Do you think early stopping would be a good solution to avoid overfitting in this case, explain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "342e80f3-8091-415c-b362-61cd2365ff7d"
    }
   },
   "source": [
    "f. [40 pts] You must have noticed that one needs to set several parametersâ€”such as the number of hidden layers, the number of neurons in each hidden layer, the non-linearity or activation function to be used, etc. These quantities are known as the hyper-parameters of the network. They need to be specified by the user creating the neural network model.\n",
    "\n",
    "In this task, you will evaluate the performance of your network for varying values of hyperparameters. Keeping the rest of the values constant (and equal to the default values), adjust the values of parameters as described below. Find the performance (accuracy) of your model on the validation set and plot a trend graph for each of the following.\n",
    "\n",
    "- Batch size: 32, 64, 128 (default 32).\n",
    "- Number of hidden layers: 1, 2, 4 (default 2).\n",
    "- SGD optimizer, Learning Rate: 0.001, 0.01, 0.1, 1 (default 0.01).\n",
    "- Use 10 epochs for all the experiments.\n",
    "- activation function Relu for all the experiments.\n",
    "\n",
    "Use these values to create the most successful model you can (evaluated based on validation scores) and report its accuracy on the test data. Keep all other hyperparameters (number of epochs, activation function, etc.) at their default settings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "40000/40000 [==============================] - 16s 404us/step - loss: 1.9239 - acc: 0.3075\n",
      "Epoch 2/10\n",
      "40000/40000 [==============================] - 11s 272us/step - loss: 1.7615 - acc: 0.3750\n",
      "Epoch 3/10\n",
      "40000/40000 [==============================] - 11s 275us/step - loss: 1.6892 - acc: 0.4051\n",
      "Epoch 4/10\n",
      "40000/40000 [==============================] - 10s 255us/step - loss: 1.6383 - acc: 0.4237\n",
      "Epoch 5/10\n",
      "40000/40000 [==============================] - 10s 258us/step - loss: 1.5992 - acc: 0.4367\n",
      "Epoch 6/10\n",
      "40000/40000 [==============================] - 10s 262us/step - loss: 1.5674 - acc: 0.4489\n",
      "Epoch 7/10\n",
      "40000/40000 [==============================] - 10s 260us/step - loss: 1.5407 - acc: 0.4574\n",
      "Epoch 8/10\n",
      "40000/40000 [==============================] - 10s 261us/step - loss: 1.5142 - acc: 0.4659\n",
      "Epoch 9/10\n",
      "40000/40000 [==============================] - 11s 266us/step - loss: 1.4916 - acc: 0.4763\n",
      "Epoch 10/10\n",
      "40000/40000 [==============================] - 13s 316us/step - loss: 1.4720 - acc: 0.4813\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_8 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 308,310\n",
      "Trainable params: 308,310\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "10000/10000 [==============================] - 3s 311us/step\n",
      "Epoch 1/10\n",
      "40000/40000 [==============================] - 17s 422us/step - loss: 1.9191 - acc: 0.3110\n",
      "Epoch 2/10\n",
      "40000/40000 [==============================] - 12s 305us/step - loss: 1.7527 - acc: 0.3797\n",
      "Epoch 3/10\n",
      "40000/40000 [==============================] - 11s 270us/step - loss: 1.6813 - acc: 0.4079\n",
      "Epoch 4/10\n",
      "40000/40000 [==============================] - 13s 313us/step - loss: 1.6323 - acc: 0.4226\n",
      "Epoch 5/10\n",
      "40000/40000 [==============================] - 12s 303us/step - loss: 1.5937 - acc: 0.4389\n",
      "Epoch 6/10\n",
      "40000/40000 [==============================] - ETA: 0s - loss: 1.5659 - acc: 0.448 - 12s 301us/step - loss: 1.5659 - acc: 0.4485\n",
      "Epoch 7/10\n",
      "40000/40000 [==============================] - 13s 317us/step - loss: 1.5359 - acc: 0.4599\n",
      "Epoch 8/10\n",
      "40000/40000 [==============================] - 12s 291us/step - loss: 1.5142 - acc: 0.4668\n",
      "Epoch 9/10\n",
      "40000/40000 [==============================] - 12s 289us/step - loss: 1.4910 - acc: 0.4767\n",
      "Epoch 10/10\n",
      "40000/40000 [==============================] - 12s 292us/step - loss: 1.4729 - acc: 0.4829\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_9 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 308,310\n",
      "Trainable params: 308,310\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "10000/10000 [==============================] - 2s 190us/step\n",
      "Epoch 1/10\n",
      "40000/40000 [==============================] - 16s 409us/step - loss: 1.9192 - acc: 0.3093\n",
      "Epoch 2/10\n",
      "40000/40000 [==============================] - 12s 297us/step - loss: 1.7424 - acc: 0.3887\n",
      "Epoch 3/10\n",
      "40000/40000 [==============================] - 12s 300us/step - loss: 1.6684 - acc: 0.4141\n",
      "Epoch 4/10\n",
      "40000/40000 [==============================] - 12s 292us/step - loss: 1.6217 - acc: 0.4285\n",
      "Epoch 5/10\n",
      "40000/40000 [==============================] - 12s 301us/step - loss: 1.5833 - acc: 0.4442\n",
      "Epoch 6/10\n",
      "40000/40000 [==============================] - 12s 301us/step - loss: 1.5528 - acc: 0.4521\n",
      "Epoch 7/10\n",
      "40000/40000 [==============================] - 13s 326us/step - loss: 1.5267 - acc: 0.4656\n",
      "Epoch 8/10\n",
      "40000/40000 [==============================] - 13s 314us/step - loss: 1.5035 - acc: 0.4706\n",
      "Epoch 9/10\n",
      "40000/40000 [==============================] - 12s 310us/step - loss: 1.4794 - acc: 0.4792\n",
      "Epoch 10/10\n",
      "40000/40000 [==============================] - 12s 311us/step - loss: 1.4612 - acc: 0.4870\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_10 (Flatten)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 308,310\n",
      "Trainable params: 308,310\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "10000/10000 [==============================] - 2s 167us/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_97 to have 4 dimensions, but got array with shape (40000, 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-193-d7ce756b0961>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msgd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain_1hot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytest_1hot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    126\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    129\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_97 to have 4 dimensions, but got array with shape (40000, 10)"
     ]
    }
   ],
   "source": [
    "batch_sizes = [32, 64, 128]\n",
    "results = [] \n",
    "\n",
    "for num in batch_sizes:\n",
    "    sgd = SGD(lr=0.01)\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(32, 32, 3)))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer=sgd,metrics=['accuracy'])\n",
    "    model.fit(xtrain, ytrain_1hot, epochs=10)\n",
    "    model.summary()\n",
    "    score = model.evaluate(xtest, ytest_1hot, batch_size=num)\n",
    "    results.append(score)\n",
    "\n",
    "print(results)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "40000/40000 [==============================] - 17s 434us/step - loss: 1.9254 - acc: 0.3100\n",
      "Epoch 2/10\n",
      "40000/40000 [==============================] - 11s 266us/step - loss: 1.7589 - acc: 0.3794\n",
      "Epoch 3/10\n",
      "40000/40000 [==============================] - 13s 323us/step - loss: 1.6835 - acc: 0.4071\n",
      "Epoch 4/10\n",
      "40000/40000 [==============================] - 16s 400us/step - loss: 1.6327 - acc: 0.4225\n",
      "Epoch 5/10\n",
      "40000/40000 [==============================] - 12s 303us/step - loss: 1.5960 - acc: 0.4362\n",
      "Epoch 6/10\n",
      "40000/40000 [==============================] - 10s 257us/step - loss: 1.5618 - acc: 0.4496\n",
      "Epoch 7/10\n",
      "40000/40000 [==============================] - 10s 259us/step - loss: 1.5404 - acc: 0.4591\n",
      "Epoch 8/10\n",
      "40000/40000 [==============================] - 11s 267us/step - loss: 1.5174 - acc: 0.4672\n",
      "Epoch 9/10\n",
      "40000/40000 [==============================] - 10s 262us/step - loss: 1.4980 - acc: 0.4729\n",
      "Epoch 10/10\n",
      "40000/40000 [==============================] - 11s 267us/step - loss: 1.4814 - acc: 0.4800\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_11 (Flatten)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 308,310\n",
      "Trainable params: 308,310\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "10000/10000 [==============================] - 2s 215us/step\n",
      "Epoch 1/10\n",
      "40000/40000 [==============================] - 15s 387us/step - loss: 1.9375 - acc: 0.3028\n",
      "Epoch 2/10\n",
      "40000/40000 [==============================] - 18s 447us/step - loss: 1.7543 - acc: 0.3756\n",
      "Epoch 3/10\n",
      "40000/40000 [==============================] - 17s 437us/step - loss: 1.6703 - acc: 0.4044\n",
      "Epoch 4/10\n",
      "40000/40000 [==============================] - 11s 280us/step - loss: 1.6208 - acc: 0.4241\n",
      "Epoch 5/10\n",
      "40000/40000 [==============================] - 12s 300us/step - loss: 1.5779 - acc: 0.4375\n",
      "Epoch 6/10\n",
      "40000/40000 [==============================] - 14s 342us/step - loss: 1.5438 - acc: 0.4547\n",
      "Epoch 7/10\n",
      "40000/40000 [==============================] - 14s 361us/step - loss: 1.5142 - acc: 0.4633\n",
      "Epoch 8/10\n",
      "40000/40000 [==============================] - 13s 326us/step - loss: 1.4929 - acc: 0.4676\n",
      "Epoch 9/10\n",
      "40000/40000 [==============================] - 13s 320us/step - loss: 1.4681 - acc: 0.4790\n",
      "Epoch 10/10\n",
      "40000/40000 [==============================] - 13s 323us/step - loss: 1.4490 - acc: 0.4843\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_12 (Flatten)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 318,410\n",
      "Trainable params: 318,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "10000/10000 [==============================] - 2s 244us/step\n",
      "Epoch 1/10\n",
      "40000/40000 [==============================] - 17s 419us/step - loss: 1.9704 - acc: 0.2861\n",
      "Epoch 2/10\n",
      "40000/40000 [==============================] - 13s 336us/step - loss: 1.7738 - acc: 0.3642\n",
      "Epoch 3/10\n",
      "40000/40000 [==============================] - 13s 336us/step - loss: 1.6866 - acc: 0.3988\n",
      "Epoch 4/10\n",
      "40000/40000 [==============================] - 13s 337us/step - loss: 1.6278 - acc: 0.4207\n",
      "Epoch 5/10\n",
      "40000/40000 [==============================] - 16s 395us/step - loss: 1.5833 - acc: 0.4338\n",
      "Epoch 6/10\n",
      "40000/40000 [==============================] - 14s 359us/step - loss: 1.5441 - acc: 0.4504\n",
      "Epoch 7/10\n",
      "40000/40000 [==============================] - 14s 354us/step - loss: 1.5154 - acc: 0.4584\n",
      "Epoch 8/10\n",
      "40000/40000 [==============================] - 14s 349us/step - loss: 1.4834 - acc: 0.4693\n",
      "Epoch 9/10\n",
      "40000/40000 [==============================] - 14s 346us/step - loss: 1.4586 - acc: 0.4790\n",
      "Epoch 10/10\n",
      "40000/40000 [==============================] - 14s 362us/step - loss: 1.4353 - acc: 0.4882\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_13 (Flatten)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_118 (Dense)            (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 338,610\n",
      "Trainable params: 338,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "10000/10000 [==============================] - 2s 241us/step\n",
      "[[1.5179409519195557, 0.4617], [1.5535020584106445, 0.4395], [1.4959261959075927, 0.4714], [1.5287206296920777, 0.4612], [1.483368382835388, 0.4684], [1.4517746728897094, 0.479]]\n"
     ]
    }
   ],
   "source": [
    "num_layers = [1,2,4]\n",
    "\n",
    "for num in num_layers:\n",
    "    sgd = SGD(lr=0.01)\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(32, 32, 3)))\n",
    "    for i in range(num):\n",
    "        model.add(Dense(100, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer=sgd,metrics=['accuracy'])\n",
    "    model.fit(xtrain, ytrain_1hot, epochs=10)\n",
    "    model.summary()\n",
    "    score = model.evaluate(xtest, ytest_1hot, batch_size=32)\n",
    "    results.append(score)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_rate = [0.001,0.01,0.1,1]\n",
    "\n",
    "for num in learn_rate:\n",
    "    sgd = SGD(lr=num)\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(32, 32, 3)))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer=sgd,metrics=['accuracy'])\n",
    "    model.fit(xtrain, ytrain_1hot, epochs=10)\n",
    "    model.summary()\n",
    "    score = model.evaluate(xtest, ytest_1hot, batch_size=32)\n",
    "    results.append(score) \n",
    "    \n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Par2 (This part is for Graduate students only, it is optional for undergraduates with extra cridets )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part you are going to train a convolutional neural network on CIFAR-10  dataset from part 1, refer to part1 to use same training, validation and testing datasets splits. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. [30 points] Define the model as indicated in the code below. The model is defined as follows:\n",
    "\n",
    "- An input that is 32x32x3 dimensional vector.\n",
    "- Reshape the input as 32x32x3 images (it is a dataset with color images)\n",
    "- A convolutional layer with 32 filters of shape 12x12x3 and a ReLU non-linearity (with stride (2, 2) and no padding)\n",
    "- A convolutional layer with 64 filters of shape 5x5x32 and a ReLU non-linearity (with stride (1, 2) and padding to maintain size)\n",
    "- A max_pooling layer of shape 2x2\n",
    "- A fully connected layer taking all the outputs of the max_pooling layer to 1024 units and ReLU nonlinearity\n",
    "- A fully connected layer taking 1024 units to 10 no activation function (the softmax non-linearity will be included in the loss function rather than in the model) \n",
    "- Use AdamOptimizer \n",
    "- use the Accuracy as your metric... Accuray is simply defined as the fraction of data correctly classified\n",
    "- initially pick the learning rate to be 0.05 (if this learning rate does not work, pick different learning rate) with decay step of 0.95 every 2000 iterations\n",
    "\n",
    "\n",
    "write the code to train the model written, train for 15 epochs with a  batch size of 128. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Hint: start from known architecture then modify the code to match the numbers listed above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. [10 points] Find better convolutional neural network architecture that give better results (at least enhancment of 5.0%) than the one built in part a (prove experimentally). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
