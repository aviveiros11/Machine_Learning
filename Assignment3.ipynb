{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Python\n",
    "\n",
    "\n",
    "For this course, we are going to use Jupyter notebook as our environment for developing Python code.\n",
    "refer to https://jupyter.readthedocs.io/en/latest/content-quickstart.html on the instructions how to install it, the easiest way is to install from Anaconda (https://www.anaconda.com/download/) website, make sure you install with Python 3.6.\n",
    "\n",
    "Also, it is good for the students who are not familiar with python (or they need a quick refreshment) to follow Jim Bagrow tutorial http://bagrow.com/ds1/whirlwindtourpython/00-Title.html. \n",
    "\n",
    "All the assignments to be written in Python 3.6 and can be run using Jupyter on one of the following Internet browsers (Chrome, Safari or Firefox), these are the browsers that officially supported by jupyter.\n",
    "\n",
    "<u> Note: for this assignment, submit your local copy of this page, running on IPython. Submit the file to Blackboard under Assignment3 using this file format:</u> <b>Yourfirstname_lastname_Assignment3.ipynb</b> \n",
    "\n",
    "#### <b>Deadline</b>: <u>Friday, Oct-18-2019 11:59 PM.</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "71b06413-b3c8-4d8a-8162-c7f97e8638ff"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "022c0cf1-20b7-4df3-bc1d-c54d2df2cf0a"
    }
   },
   "source": [
    "# Assignment 3 -- Part 1\n",
    "\n",
    "In this part, you will use SVM from sklearn to classify non-linearly sperable datasets. \n",
    "\n",
    "Hint: Refer to the example in sklearn http://scikit-learn.org/stable/auto_examples/svm/plot_iris.html, you can use this code or part of it in your solutions.\n",
    "\n",
    "Load (using load_breast_cancer) datasets from sklearn (datasets.load_breast_cancer()):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "66155e44-4f44-45fe-a733-8feb6bf79904"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "7b5712e6-b08b-4c78-96e5-d6c179cb2216"
    }
   },
   "source": [
    "### Part 1, Q1  --  [25 pts]\n",
    "\n",
    "1. In this question, you need to find the best SVM kernel that fit the data. Use built-in SVM functions from scikit learn Library. Evaluate 'linear', 'poly', 'rbf', 'sigmoid' Kernels using the default parameters as they aren't biased towards one of the kernels. Remember that in order to evaluate kernels or any hyper param you need to use cross-validation method. use k=50 for this question. Comment on the results.\n",
    "\n",
    "2. Which scoring metric you would like to use? justify your answer.\n",
    "\n",
    "Note: You can use built-in scikit learn function for this question and all other questions in this assignment else it is mentioned not to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "3a0e4064-e0d5-43bd-8793-4ce5742de906"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "342e80f3-8091-415c-b362-61cd2365ff7d"
    }
   },
   "source": [
    "### Part 1, Q2  --  [25 pts]\n",
    "\n",
    "Using random search, what are the optimum hyperparameters for each kernel? \n",
    "For this question, use only a few numbers of iterations when you do a random search (no need to run for long hours). Add to that, also be smart when you select the scale for the C, gamma and class_weight so that you can find the best params. Which SVM kernel achieving the highest performance?\n",
    "\n",
    "Note: You can use RandomizedSearchCV function from the scikit learn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "a90d24af-7c70-415a-9909-495ba485a1bf"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "f552aeba-4559-461d-882a-823ba5425db4"
    }
   },
   "source": [
    "### (Graduate students only)\n",
    "\n",
    "### Part 1, Q3  --  [10 pts]\n",
    "\n",
    "Randomly select 20% of the data for testing and the rest for training.\n",
    "\n",
    "Plot the decision surface for \"worse SVM\", \"best SVM\" found in part b and report the performance for each, you may use built-in sklean functions for visualization.\n",
    "\n",
    "Note: For visualization you need to work on two-dimensional feature space. To do so, use PCA to reduce the number of the features to 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "cd1818e8-bb92-403c-af51-aaad4450235e"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "394b37bb-6e40-422e-b3c9-c622c46ab976"
    }
   },
   "source": [
    "# Assignment 3 -- Part 2\n",
    "\n",
    "In this part, you will use the decision tree from sklearn to classify non-linearly separable datasets. \n",
    "\n",
    "\n",
    "Load Car Evaluation Data Set from https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data, read the dataset description and get familiar with the dataset attributes https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.names\n",
    "\n",
    "This dataset includes strings, you might need to convert them to numbers, in this case, you might need to use methods like preprocessing.LabelEncoder(). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "06adccbc-446c-49c2-af1a-5688479b7251"
    }
   },
   "source": [
    "### Part 2, Q1-- [25 pts]\n",
    "\n",
    "Use the decision tree to classify the dataset (evaluate cars to one of the four classes unacc, acc, good, v-good). Use cross-validation while reporting your results. You can use sklearn.tree.DecisionTreeClassifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "f9acd257-ab12-4275-868d-133fd6e2e5ae"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "f97aa916-f0ed-4776-95e7-2e92c66f1add"
    }
   },
   "source": [
    "### Part 1, Q2 [25 pts]\n",
    "\n",
    "What is the optimum min_samples_split (The minimum number of samples required to split an internal node), does it make sense? Why?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "fceba820-64d6-40e3-9223-36de70bac16b"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "d83b28ba-d22d-415e-9ccd-32f809507501"
    }
   },
   "source": [
    "### (Graduate students only)\n",
    "\n",
    "### Part 1, Q3 [15 pts]\n",
    "\n",
    "Implement random forest classifier by defining multiple (DecisionTreeClassifier)'s from sklearn. You can use the max_features from DecisionTreeClassifier. Lastly, compare your results to RandomForestClassifier from sklearn.\n",
    "\n",
    "Note: In this part implement the bagging/ensemble by yourself without calling built-in functions from sklearn (you may still use RandomForestClassifier from sklearn with max_features).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
